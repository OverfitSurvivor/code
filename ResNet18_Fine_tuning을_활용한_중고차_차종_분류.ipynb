{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OverfitSurvivor/code/blob/main/ResNet18_Fine_tuning%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%A4%91%EA%B3%A0%EC%B0%A8_%EC%B0%A8%EC%A2%85_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3kv-bdfJM_5"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6VMtzJ4BSdRx",
        "outputId": "bc3a84c0-696d-4c22-84be-52ee26631bb8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/car_hecto.zip'\n",
        "extract_path = '/content//car_hecto_unzipped'\n",
        "\n",
        "# 압축 해제할 디렉토리가 없으면 생성\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# zipfile을 이용한 압축 해제\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"압축이 해제되었습니다: {extract_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z0NDSg_54UzM",
        "outputId": "ab90920f-b4de-492d-ee68-11a0bfe1429f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축이 해제되었습니다: /content//car_hecto_unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-rEM0A-dJM_-",
        "outputId": "6d909b5a-a9dd-458b-c631-e0c65d122aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ruzMOYJNAB"
      },
      "source": [
        "# Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uTTs751ZJNAC"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE': 224,\n",
        "    'BATCH_SIZE': 64,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE': 1e-4,\n",
        "    'SEED' : 42\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FfyuLSZJNAD"
      },
      "source": [
        "# Fixed RandomSeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YqECtn2cJNAE"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6e4Vju8JNAF"
      },
      "source": [
        "# CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5luwd_ObJNAF"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if is_test:\n",
        "            # 테스트셋: 라벨 없이 이미지 경로만 저장\n",
        "            for fname in sorted(os.listdir(root_dir)):\n",
        "                if fname.lower().endswith(('.jpg')):\n",
        "                    img_path = os.path.join(root_dir, fname)\n",
        "                    self.samples.append((img_path,))\n",
        "        else:\n",
        "            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n",
        "            self.classes = sorted(os.listdir(root_dir))\n",
        "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "            for cls_name in self.classes:\n",
        "                cls_folder = os.path.join(root_dir, cls_name)\n",
        "                for fname in os.listdir(cls_folder):\n",
        "                    if fname.lower().endswith(('.jpg')):\n",
        "                        img_path = os.path.join(cls_folder, fname)\n",
        "                        label = self.class_to_idx[cls_name]\n",
        "                        self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            img_path = self.samples[idx][0]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image\n",
        "        else:\n",
        "            img_path, label = self.samples[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzfbrB6eJNAH"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XbHO-ts7JNAH"
      },
      "outputs": [],
      "source": [
        "train_root = '/content/car_hecto_unzipped/train'\n",
        "test_root = '/content/car_hecto_unzipped/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "94ZBOrLgJNAI"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EUAXPo38JNAJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "12989de0-0b53-43a1-f2bd-199547d24692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 이미지 수: 33137\n",
            "train 이미지 수: 26509, valid 이미지 수: 6628\n"
          ]
        }
      ],
      "source": [
        "# 전체 데이터셋 로드\n",
        "full_dataset = CustomImageDataset(train_root, transform=None)\n",
        "print(f\"총 이미지 수: {len(full_dataset)}\")\n",
        "\n",
        "targets = [label for _, label in full_dataset.samples]\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "# Stratified Split\n",
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
        ")\n",
        "\n",
        "# Subset + transform 각각 적용\n",
        "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
        "print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n",
        "\n",
        "\n",
        "# DataLoader 정의\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCz3TcMTJNAK"
      },
      "source": [
        "# Model Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "62lX7QTpJNAK"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.backbone = models.resnet18(pretrained=True)  # ResNet18 모델 불러오기\n",
        "        self.feature_dim = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n",
        "        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ScZYXygJNAL"
      },
      "source": [
        "# Train/ Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2pn4RoMPJNAL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7ca9bab5-78de-445d-b37f-d7363d4b96a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 174MB/s]\n",
            "[Epoch 1/10] Training: 100%|██████████| 415/415 [04:53<00:00,  1.42it/s]\n",
            "[Epoch 1/10] Validation: 100%|██████████| 104/104 [00:51<00:00,  2.03it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 4.1608 || Valid Loss : 2.2727 | Valid Accuracy : 70.5190%\n",
            "📦 Best model saved at epoch 1 (logloss: 2.2713)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 2/10] Training: 100%|██████████| 415/415 [04:18<00:00,  1.60it/s]\n",
            "[Epoch 2/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.18it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 1.2921 || Valid Loss : 0.7625 | Valid Accuracy : 86.6476%\n",
            "📦 Best model saved at epoch 2 (logloss: 0.7619)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 3/10] Training: 100%|██████████| 415/415 [04:13<00:00,  1.64it/s]\n",
            "[Epoch 3/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.19it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.4181 || Valid Loss : 0.4618 | Valid Accuracy : 91.0229%\n",
            "📦 Best model saved at epoch 3 (logloss: 0.4610)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 4/10] Training: 100%|██████████| 415/415 [04:14<00:00,  1.63it/s]\n",
            "[Epoch 4/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.19it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.1690 || Valid Loss : 0.3833 | Valid Accuracy : 92.1847%\n",
            "📦 Best model saved at epoch 4 (logloss: 0.3826)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 5/10] Training: 100%|██████████| 415/415 [04:13<00:00,  1.63it/s]\n",
            "[Epoch 5/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.19it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.0796 || Valid Loss : 0.3343 | Valid Accuracy : 92.9390%\n",
            "📦 Best model saved at epoch 5 (logloss: 0.3335)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 6/10] Training: 100%|██████████| 415/415 [04:15<00:00,  1.62it/s]\n",
            "[Epoch 6/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.21it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.0430 || Valid Loss : 0.2999 | Valid Accuracy : 92.9541%\n",
            "📦 Best model saved at epoch 6 (logloss: 0.2991)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 7/10] Training: 100%|██████████| 415/415 [04:15<00:00,  1.63it/s]\n",
            "[Epoch 7/10] Validation: 100%|██████████| 104/104 [00:46<00:00,  2.22it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.0262 || Valid Loss : 0.2783 | Valid Accuracy : 93.6180%\n",
            "📦 Best model saved at epoch 7 (logloss: 0.2774)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 8/10] Training: 100%|██████████| 415/415 [04:15<00:00,  1.63it/s]\n",
            "[Epoch 8/10] Validation: 100%|██████████| 104/104 [00:46<00:00,  2.22it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.0174 || Valid Loss : 0.2587 | Valid Accuracy : 93.7990%\n",
            "📦 Best model saved at epoch 8 (logloss: 0.2580)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 9/10] Training: 100%|██████████| 415/415 [04:14<00:00,  1.63it/s]\n",
            "[Epoch 9/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.18it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.0129 || Valid Loss : 0.2546 | Valid Accuracy : 93.8896%\n",
            "📦 Best model saved at epoch 9 (logloss: 0.2541)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 10/10] Training: 100%|██████████| 415/415 [04:14<00:00,  1.63it/s]\n",
            "[Epoch 10/10] Validation: 100%|██████████| 104/104 [00:47<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss : 0.0136 || Valid Loss : 0.2799 | Valid Accuracy : 93.4822%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = BaseModel(num_classes=len(class_names)).to(device)\n",
        "best_logloss = float('inf')\n",
        "\n",
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
        "\n",
        "# 학습 및 검증 루프\n",
        "for epoch in range(CFG['EPOCHS']):\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)  # logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Accuracy\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # LogLoss\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
        "\n",
        "    # Best model 저장\n",
        "    if val_logloss < best_logloss:\n",
        "        best_logloss = val_logloss\n",
        "        torch.save(model.state_dict(), f'best_model.pth')\n",
        "        print(f\"📦 Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6HCKiYnJNAM"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WEDias_qJNAM"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e0AfXPsoJNAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f3410b51-b3fe-466a-cf70-e509728c1e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# 저장된 모델 로드\n",
        "model = BaseModel(num_classes=len(class_names))\n",
        "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# 추론\n",
        "model.eval()\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        # 각 배치의 확률을 리스트로 변환\n",
        "        for prob in probs.cpu():  # prob: (num_classes,)\n",
        "            result = {\n",
        "                class_names[i]: prob[i].item()\n",
        "                for i in range(len(class_names))\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "pred = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBQk9EBJNAN"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aFr3VRhNJNAO"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('/content/car_hecto_unzipped/sample_submission.csv', encoding='utf-8-sig')\n",
        "\n",
        "# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n",
        "class_columns = submission.columns[1:]\n",
        "pred = pred[class_columns]\n",
        "\n",
        "submission[class_columns] = pred.values\n",
        "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}